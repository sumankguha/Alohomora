{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICSS Data analysis script\n",
    "\n",
    "## README\n",
    "A template to analyze ICSS data from output files to plot. The motivation is to perform reproducible research by standardizing the steps that are performed for data analysis and statistical inference. \n",
    "\n",
    "### OUTLINE:\n",
    "0. Prerequisite: CSV files of ICSS data files generated using the script written by Steve Cabilio\n",
    "1. Preprocessing\n",
    "2. \n",
    "\n",
    "---\n",
    "\n",
    "### Author(s): Suman K. Guha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ICSS data preprocessing \n",
    "As a prerequisite of analysis is to convert the data MedPC generated data to Theta0, M50, and Max Rate, using Steve Cabilio's program. **Note:** We use the CSV program as it is an open format and easier to work with. \n",
    "\n",
    "A typical file generated by the analysis program looks like\n",
    "\n",
    "    Source:,C:\\ICSS\\EC-IVSA\\RF\\SG13\\20190117.XLS\n",
    "\n",
    "    Data_File,Box,Subject,Group,Experiment,End Date,End Time,MPC,Comment\n",
    "    C:\\ICSS\\EC-IVSA\\RF\\SG13\\20190117.XLS,1,SG13,RF,EC-IVSA,2019-01-17,11:57:23,ICSS4_01,Generated by macro C:\\MED-PC IV\\Macro\\2019_RF_ICSS+IVSA_G1-PM_1 1/17/2019 10:50:26 AM\n",
    "\n",
    "    Pulse1w,uAmp1,Pulse1Pulse2,Pulse2w,uAmp2,StimDur,StimDelay,TimeOut,TrialDur,ITI,NumPrimes,InterPrime,PrimeDelay,FR\n",
    "    100,0,100,100,170,500,0,0.5,50,10,5,500,5500,1\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50,72.22,78.28,58.25,74.78\n",
    "    T0,37.61,50.42,49.50,63.00\n",
    "    MaxR,275,177,241,212\n",
    "    Slope,210.71,201.21,740.44,618.61\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50 Mean,72.22,78.28,58.25,74.78\n",
    "    T0 Mean,37.61,50.42,49.50,63.00\n",
    "    MaxR Mean,275.00,177.00,241.00,212.00\n",
    "    Slope Mean,210.71,201.21,740.44,618.61\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50 %Baseline,100.00,108.39,80.65,103.54\n",
    "    T0 %Baseline,100.00,134.08,131.62,167.52\n",
    "    MaxR %Baseline,100.00,64.36,87.64,77.09\n",
    "    Slope %Baseline,100.00,95.49,351.40,293.58\n",
    "\n",
    "Once we run the preprocessing step it looks like\n",
    "\n",
    "    Date,Subject,Experiment,Pass,T0,M50,MaxRate\n",
    "    2019-01-17,SG13,RF,1,37.61,72.22,275\n",
    "    2019-01-17,SG13,RF,2,50.42,78.28,177\n",
    "    2019-01-17,SG13,RF,3,49.50,58.25,241\n",
    "    2019-01-17,SG13,RF,4,63.00,74.78,212\n",
    "    \n",
    "In the next step we are going to batch process this conversion step by looping over all the files. For us to be able to do that, we need to have very rigid file structures. A typical file structure _**should**_ be\n",
    "   \n",
    "    Cohort01\n",
    "    |\n",
    "    |---Subject01\n",
    "    |   |\n",
    "    |   ANA_<YYYYMMDD>.CSV\n",
    "    |\n",
    "    |---Subject02\n",
    "    |   |\n",
    "        ANA_<YYYYMMDD>.CSV\n",
    "\n",
    "For the preprocessing part, we extract the values of each animal, for each day. After that is performed we will combine and store them in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "# this line makes the script machine agnostic by assigning the username automatically\n",
    "userName=$(echo $USER)\n",
    "\n",
    "# We move to the folder where the cohort data is stored\n",
    "# cd </path/to/cohort/data>\n",
    "cd /Users/$userName/Dropbox\\ \\(Partners\\ HealthCare\\)/Projects/R01_2017_OxycSA-NASh-Glutamate/_data_R01_2017/_data_R01_2017_ICSS/_ana_files/Cohort01\n",
    "\n",
    "# entering each subject/animal directory to list all the CSV files and to run the program on each\n",
    "for dirName in $(ls -d */)\n",
    "do\n",
    "    cd $dirName\n",
    "    for fileName in $(ls ANA*.CSV)\n",
    "    do\n",
    "        preprocessICSSFiles --file $fileName;\n",
    "    done\n",
    "    cd ..\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%R\n",
    "# loading required libraries for R\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "# 1. loading data: set the path to \n",
    "dataDir <- \"~/Dropbox (Partners HealthCare)/Projects/R01_2017_OxycSA-NASh-Glutamate/_data_R01_2017/_data_R01_2017_ICSS/_ana_files/Cohort01/\"\n",
    "fileList <- list.files(path = dataDir, pattern = \"preprocessed.csv\", recursive = T)\n",
    "## generating combined data table\n",
    "data <- fileList %>% map(~ read_csv(file.path(dataDir, .))) %>% reduce(rbind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 1,096 x 7\u001b[39m\n",
       "   Date       Subject Experiment  Pass T0    M50   MaxRate\n",
       "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
       "\u001b[90m 1\u001b[39m 2019-01-17 SG13    RF             1 37.61 72.22     275\n",
       "\u001b[90m 2\u001b[39m 2019-01-17 SG13    RF             2 50.42 78.28     177\n",
       "\u001b[90m 3\u001b[39m 2019-01-17 SG13    RF             3 49.5  58.25     241\n",
       "\u001b[90m 4\u001b[39m 2019-01-17 SG13    RF             4 63    74.78     212\n",
       "\u001b[90m 5\u001b[39m 2019-01-18 SG13    RF             1 33.77 55.55     201\n",
       "\u001b[90m 6\u001b[39m 2019-01-18 SG13    RF             2 59.77 69.08     165\n",
       "\u001b[90m 7\u001b[39m 2019-01-18 SG13    RF             3 62.66 77.56     168\n",
       "\u001b[90m 8\u001b[39m 2019-01-18 SG13    RF             4 57.85 81.47     158\n",
       "\u001b[90m 9\u001b[39m 2019-01-22 SG13    RF             1 38.03 46.48     282\n",
       "\u001b[90m10\u001b[39m 2019-01-22 SG13    RF             2 33.38 52.09     340\n",
       "\u001b[90m# ... with 1,086 more rows\u001b[39m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "data %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 1,096 x 7\u001b[39m\n",
       "   Date       Subject Experiment  Pass    T0   M50 MaxRate\n",
       "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
       "\u001b[90m 1\u001b[39m 2019-01-17 SG13    RF             1  37.6  72.2     275\n",
       "\u001b[90m 2\u001b[39m 2019-01-17 SG13    RF             2  50.4  78.3     177\n",
       "\u001b[90m 3\u001b[39m 2019-01-17 SG13    RF             3  49.5  58.2     241\n",
       "\u001b[90m 4\u001b[39m 2019-01-17 SG13    RF             4  63    74.8     212\n",
       "\u001b[90m 5\u001b[39m 2019-01-18 SG13    RF             1  33.8  55.6     201\n",
       "\u001b[90m 6\u001b[39m 2019-01-18 SG13    RF             2  59.8  69.1     165\n",
       "\u001b[90m 7\u001b[39m 2019-01-18 SG13    RF             3  62.7  77.6     168\n",
       "\u001b[90m 8\u001b[39m 2019-01-18 SG13    RF             4  57.8  81.5     158\n",
       "\u001b[90m 9\u001b[39m 2019-01-22 SG13    RF             1  38.0  46.5     282\n",
       "\u001b[90m10\u001b[39m 2019-01-22 SG13    RF             2  33.4  52.1     340\n",
       "\u001b[90m# ... with 1,086 more rows\u001b[39m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# 2. Cleaning data\n",
    "# re-assigning data types to individual columns. This gets broken when there are missing values\n",
    "# Ideal data types\n",
    "# Date   | Subject  | Experiment | Pass  | T0    |  M50  | MaxRate\n",
    "# <date> | <factor> |  <factor>  | <num> | <num> | <num> |  <num>\n",
    "\n",
    "data$Subject <- data$Subject %>% as.factor\n",
    "data$Experiment <- data$Experiment %>% as.factor\n",
    "data$T0 <- data$T0 %>% as.numeric\n",
    "data$M50 <- data$M50 %>% as.numeric\n",
    "data %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Date[1:1096], format: \"2019-01-17\" \"2019-01-17\" \"2019-01-17\" \"2019-01-17\" \"2019-01-18\" ...\n",
       " [1] \"2019-01-17\" \"2019-01-18\" \"2019-01-22\" \"2019-01-23\" \"2019-01-24\"\n",
       " [6] \"2019-01-25\" \"2019-01-28\" \"2019-01-29\" \"2019-01-30\" \"2019-02-01\"\n",
       "[11] \"2019-02-04\" \"2019-02-06\" \"2019-02-07\" \"2019-02-08\" \"2019-02-18\"\n",
       "[16] \"2019-02-19\" \"2019-02-20\" \"2019-02-21\" \"2019-02-22\" \"2019-02-25\"\n",
       "[21] \"2019-02-26\" \"2019-02-27\" \"2019-02-28\" \"2019-03-01\" \"2019-03-04\"\n",
       "[26] \"2019-03-05\" \"2019-03-06\" \"2019-03-07\" \"2019-03-08\" \"2019-03-11\"\n",
       "[31] \"2019-03-12\" \"2019-03-13\" \"2019-03-14\" \"2019-03-15\" \"2019-03-18\"\n",
       "[36] \"2019-03-19\" \"2019-03-20\" \"2019-03-21\" \"2019-03-22\" \"2019-03-25\"\n",
       "[41] \"2019-03-26\" \"2019-03-27\" \"2019-03-28\" \"2019-03-29\" \"2019-04-01\"\n",
       "[46] \"2019-04-02\" \"2019-01-31\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# 3. Checking out the data\n",
    "# Dates over which the experiment has run\n",
    "data$Date %>% str()\n",
    "data$Date %>% unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Factor w/ 7 levels \"SG13\",\"SG14\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
       "[1] SG13 SG14 SG15 SG17 SG19 SG20 SG24\n",
       "Levels: SG13 SG14 SG15 SG17 SG19 SG20 SG24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# 3. Checking out data\n",
    "# Subjects in the experiment over which the experiment has run\n",
    "data$Subject %>% str()\n",
    "data$Subject %>% unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 4. Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
