{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICSS Data analysis script\n",
    "\n",
    "## README\n",
    "A template to analyze ICSS data from output files to plot. The motivation is to perform reproducible research by standardizing the steps that are performed for data analysis and statistical inference. \n",
    "\n",
    "### OUTLINE:\n",
    "0. Prerequisite: CSV files of ICSS data files generated using the script written by Steve Cabilio\n",
    "1. Preprocessing\n",
    "2. \n",
    "\n",
    "---\n",
    "\n",
    "### Author(s): Suman K. Guha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ICSS data preprocessing \n",
    "As a prerequisite of analysis is to convert the data MedPC generated data to Theta0, M50, and Max Rate, using Steve Cabilio's program. **Note:** We use the CSV program as it is an open format and easier to work with. \n",
    "\n",
    "A typical file generated by the analysis program looks like\n",
    "\n",
    "    Source:,C:\\ICSS\\EC-IVSA\\RF\\SG13\\20190117.XLS\n",
    "\n",
    "    Data_File,Box,Subject,Group,Experiment,End Date,End Time,MPC,Comment\n",
    "    C:\\ICSS\\EC-IVSA\\RF\\SG13\\20190117.XLS,1,SG13,RF,EC-IVSA,2019-01-17,11:57:23,ICSS4_01,Generated by macro C:\\MED-PC IV\\Macro\\2019_RF_ICSS+IVSA_G1-PM_1 1/17/2019 10:50:26 AM\n",
    "\n",
    "    Pulse1w,uAmp1,Pulse1Pulse2,Pulse2w,uAmp2,StimDur,StimDelay,TimeOut,TrialDur,ITI,NumPrimes,InterPrime,PrimeDelay,FR\n",
    "    100,0,100,100,170,500,0,0.5,50,10,5,500,5500,1\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50,72.22,78.28,58.25,74.78\n",
    "    T0,37.61,50.42,49.50,63.00\n",
    "    MaxR,275,177,241,212\n",
    "    Slope,210.71,201.21,740.44,618.61\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50 Mean,72.22,78.28,58.25,74.78\n",
    "    T0 Mean,37.61,50.42,49.50,63.00\n",
    "    MaxR Mean,275.00,177.00,241.00,212.00\n",
    "    Slope Mean,210.71,201.21,740.44,618.61\n",
    "\n",
    "    ,Pass1,Pass2,Pass3,Pass4\n",
    "    M50 %Baseline,100.00,108.39,80.65,103.54\n",
    "    T0 %Baseline,100.00,134.08,131.62,167.52\n",
    "    MaxR %Baseline,100.00,64.36,87.64,77.09\n",
    "    Slope %Baseline,100.00,95.49,351.40,293.58\n",
    "\n",
    "Once we run the preprocessing step it looks like\n",
    "\n",
    "    Date,Subject,Experiment,Pass,T0,M50,MaxRate\n",
    "    2019-01-17,SG13,RF,1,37.61,72.22,275\n",
    "    2019-01-17,SG13,RF,2,50.42,78.28,177\n",
    "    2019-01-17,SG13,RF,3,49.50,58.25,241\n",
    "    2019-01-17,SG13,RF,4,63.00,74.78,212\n",
    "    \n",
    "In the next step we are going to batch process this conversion step by looping over all the files. For us to be able to do that, we need to have very rigid file structures. A typical file structure _**should**_ be\n",
    "   \n",
    "    Cohort01\n",
    "    |\n",
    "    |---Subject01\n",
    "    |   |\n",
    "    |   ANA_<YYYYMMDD>.CSV\n",
    "    |\n",
    "    |---Subject02\n",
    "    |   |\n",
    "        ANA_<YYYYMMDD>.CSV\n",
    "\n",
    "For the preprocessing part, we extract the values of each animal, for each day. After that is performed we will combine and store them in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "# We move to the folder where the cohort data is stored\n",
    "# cd </path/to/cohort/data>\n",
    "cd /Users/sumanguha/Dropbox\\ \\(Partners\\ HealthCare\\)/Projects/R01_2017_OxycSA-NASh-Glutamate/_data_R01_2017/_data_R01_2017_ICSS/_ana_files/Cohort01\n",
    "\n",
    "# entering each subject/animal directory to list all the CSV files and to run the program on each\n",
    "for dirName in $(ls -d */)\n",
    "do\n",
    "    cd $dirName\n",
    "    for fileName in $(ls ANA*.CSV)\n",
    "    do\n",
    "        preprocessICSSFiles --file $fileName;\n",
    "    done\n",
    "    cd ..\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the interface that will let us talk to the R Statistical programing language\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%R\n",
    "# loading required libraries for R\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "# 1. loading data: set the path to \n",
    "dataDir <- \"~/Dropbox (Partners HealthCare)/Projects/R01_2017_OxycSA-NASh-Glutamate/_data_R01_2017/_data_R01_2017_ICSS/_ana_files/Cohort01/\"\n",
    "fileList <- list.files(path = dataDir, pattern = \"preprocessed.csv\", recursive = T)\n",
    "## generating combined data table\n",
    "data <- fileList %>% map(~ read_csv(file.path(dataDir, .))) %>% reduce(rbind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 812 x 7\u001b[39m\n",
       "   Date       Subject Experiment  Pass T0    M50   MaxRate\n",
       "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[90m 1\u001b[39m 2019-01-17 SG13    RF             1 37.61 72.22     275\n",
       "\u001b[90m 2\u001b[39m 2019-01-17 SG13    RF             2 50.42 78.28     177\n",
       "\u001b[90m 3\u001b[39m 2019-01-17 SG13    RF             3 49.5  58.25     241\n",
       "\u001b[90m 4\u001b[39m 2019-01-17 SG13    RF             4 63    74.78     212\n",
       "\u001b[90m 5\u001b[39m 2019-01-18 SG13    RF             1 33.77 55.55     201\n",
       "\u001b[90m 6\u001b[39m 2019-01-18 SG13    RF             2 59.77 69.08     165\n",
       "\u001b[90m 7\u001b[39m 2019-01-18 SG13    RF             3 62.66 77.56     168\n",
       "\u001b[90m 8\u001b[39m 2019-01-18 SG13    RF             4 57.85 81.47     158\n",
       "\u001b[90m 9\u001b[39m 2019-01-22 SG13    RF             1 38.03 46.48     282\n",
       "\u001b[90m10\u001b[39m 2019-01-22 SG13    RF             2 33.38 52.09     340\n",
       "\u001b[90m# ... with 802 more rows\u001b[39m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "data %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
